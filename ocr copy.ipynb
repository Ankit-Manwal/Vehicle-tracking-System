{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55dc739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import re\n",
    "import torch\n",
    "from collections import defaultdict, deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d95acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691bec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"saved_models/license_plate_best.pt\")\n",
    "model.to(\"cuda\")  # move YOLO to GPU\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\n",
    "\n",
    "# 2 letters + 2 numbers + 3 letters\n",
    "plate_pattern = re.compile(r\"^[A-Z]{2}[0-9]{2}[A-Z]{3}$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bd6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 4️⃣ Function to correct OCR mistakes\n",
    "# ---------------------------------------------------\n",
    "def correct_plate_format(ocr_text):\n",
    "    \"\"\"\n",
    "    Corrects common OCR mistakes in license plates.\n",
    "    Expected format: AA11AAA\n",
    "    \"\"\"\n",
    "\n",
    "    # Mapping numbers that often look like letters\n",
    "    mapping_num_to_alpha = {\n",
    "        \"0\": \"O\",\n",
    "        \"1\": \"I\",\n",
    "        \"5\": \"S\",\n",
    "        \"8\": \"B\"\n",
    "    }\n",
    "\n",
    "    # Mapping letters that often look like numbers\n",
    "    mapping_alpha_to_num = {\n",
    "        \"O\": \"0\",\n",
    "        \"I\": \"1\",\n",
    "        \"Z\": \"2\",\n",
    "        \"S\": \"5\",\n",
    "        \"B\": \"8\"\n",
    "    }\n",
    "\n",
    "    # Clean the OCR text\n",
    "    ocr_text = ocr_text.upper().replace(\" \", \"\")\n",
    "\n",
    "    # If length is not 7 → discard\n",
    "    if len(ocr_text) != 7:\n",
    "        return \"\"\n",
    "\n",
    "    corrected = []\n",
    "\n",
    "    # Loop through each character\n",
    "    for i, ch in enumerate(ocr_text):\n",
    "\n",
    "        # ------------------------------------------\n",
    "        # Alphabet positions (0,1 and 4,5,6)\n",
    "        # ------------------------------------------\n",
    "        if i < 2 or i >= 4:\n",
    "\n",
    "            # If digit found in alphabet position → convert if possible\n",
    "            if ch.isdigit() and ch in mapping_num_to_alpha:\n",
    "                corrected.append(mapping_num_to_alpha[ch])\n",
    "\n",
    "            # If already alphabet → keep it\n",
    "            elif ch.isalpha():\n",
    "                corrected.append(ch)\n",
    "\n",
    "            # Invalid character\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "        # ------------------------------------------\n",
    "        # Numeric positions (2,3)\n",
    "        # ------------------------------------------\n",
    "        else:\n",
    "\n",
    "            # If alphabet found in numeric position → convert if possible\n",
    "            if ch.isalpha() and ch in mapping_alpha_to_num:\n",
    "                corrected.append(mapping_alpha_to_num[ch])\n",
    "\n",
    "            # If already digit → keep it\n",
    "            elif ch.isdigit():\n",
    "                corrected.append(ch)\n",
    "\n",
    "            # Invalid character\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "    return \"\".join(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15393ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "def recognize_plate(plate_crop):\n",
    "    \"\"\"\n",
    "    Takes a cropped license plate image\n",
    "    Runs preprocessing + OCR\n",
    "    Returns a corrected and validated plate string\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 1️⃣ Safety check (empty crop)\n",
    "    # -----------------------------------------\n",
    "    if plate_crop is None or plate_crop.size == 0:\n",
    "        return \"\"\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2️⃣ Preprocessing for better OCR accuracy\n",
    "    # -----------------------------------------\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply OTSU thresholding (automatic binarization)\n",
    "    _, thresh = cv2.threshold(\n",
    "        gray,\n",
    "        0,\n",
    "        255,\n",
    "        cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # Resize image (increase size improves OCR accuracy)\n",
    "    plate_resized = cv2.resize(\n",
    "        thresh,\n",
    "        None,\n",
    "        fx=2,\n",
    "        fy=2,\n",
    "        interpolation=cv2.INTER_CUBIC\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3️⃣ Run EasyOCR\n",
    "    # -----------------------------------------\n",
    "    try:\n",
    "        ocr_result = reader.readtext(\n",
    "            plate_resized,\n",
    "            detail=0,  # only return text\n",
    "            allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "        )\n",
    "\n",
    "        # -------------------------------------\n",
    "        # 4️⃣ Validate and correct result\n",
    "        # -------------------------------------\n",
    "        if len(ocr_result) > 0:\n",
    "\n",
    "            # Take first detected string\n",
    "            candidate = correct_plate_format(ocr_result[0])\n",
    "\n",
    "            # Check against regex pattern\n",
    "            if candidate and plate_pattern.match(candidate):\n",
    "                return candidate\n",
    "\n",
    "    except Exception as e:\n",
    "        # You can print error for debugging\n",
    "        # print(\"OCR Error:\", e)\n",
    "        pass\n",
    "\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dde953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict, deque\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Store last 10 OCR predictions per detected box\n",
    "# --------------------------------------------------\n",
    "plate_history = defaultdict(lambda: deque(maxlen=10))\n",
    "\n",
    "# Store final stable plate result per box\n",
    "plate_final = {}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Generate a pseudo ID for each bounding box\n",
    "# --------------------------------------------------\n",
    "def get_box_id(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Creates a pseudo ID using rounded box coordinates.\n",
    "    This helps track the same plate across frames.\n",
    "    \"\"\"\n",
    "    return f\"{int(x1/10)}_{int(y1/10)}_{int(x2/10)}_{int(y2/10)}\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Stabilize OCR result using majority voting\n",
    "# --------------------------------------------------\n",
    "def get_stable_plate(box_id, new_text):\n",
    "    \"\"\"\n",
    "    Maintains history of OCR predictions for a plate\n",
    "    and returns the most frequent (stable) result.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add new OCR prediction to history\n",
    "    if new_text:\n",
    "        plate_history[box_id].append(new_text)\n",
    "\n",
    "        # Majority voting (most common value)\n",
    "        most_common = max(\n",
    "            set(plate_history[box_id]),\n",
    "            key=plate_history[box_id].count\n",
    "        )\n",
    "\n",
    "        # Save stable result\n",
    "        plate_final[box_id] = most_common\n",
    "\n",
    "    # Return stable plate (or empty if none)\n",
    "    return plate_final.get(box_id, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51395346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Input / Output video paths\n",
    "# --------------------------------------------------\n",
    "input_video = \"test_images_and_videos/video4.mp4\"\n",
    "output_video = \"output_with_license_v3.mp4\"\n",
    "\n",
    "frame_size_1=1280\n",
    "frame_size_2=720\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Open input video\n",
    "# --------------------------------------------------\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Error: Cannot open video file\")\n",
    "    exit()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Get video properties\n",
    "# --------------------------------------------------\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# width = int(cap.get(3))\n",
    "# height = int(cap.get(4))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Define codec and create VideoWriter\n",
    "# mp4v works well for .mp4 files\n",
    "# --------------------------------------------------\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "out = cv2.VideoWriter(\n",
    "    output_video,\n",
    "    fourcc,\n",
    "    fps,\n",
    "    (width, height)\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Detection confidence threshold\n",
    "# --------------------------------------------------\n",
    "CONF_THRESH = 0.3\n",
    "\n",
    "# Load pre-created mask image (white = keep, black = ignore)\n",
    "road_mask = cv2.imread(\"test_images_and_videos/mask4.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if road_mask is None:\n",
    "    print(\"❌ Mask image not found\")\n",
    "    exit()\n",
    "\n",
    "road_mask = cv2.resize(road_mask, (frame_size_1, frame_size_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f662d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m frame = cv2.resize(frame, (frame_size_1, frame_size_2))\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# masked_frame = cv2.bitwise_and(frame, road_mask)  # overlap mask and actual video to get only counting area\u001b[39;00m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Resize mask to match frame size\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# mask_resized = cv2.resize(road_mask, (frame.shape[1], frame.shape[0]))\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Apply mask\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m frame_masked = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitwise_and\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroad_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# YOLO detection\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# results = model(frame, verbose=False)   # cpu\u001b[39;00m\n\u001b[32m     23\u001b[39m results = model(frame_masked, device=\u001b[32m0\u001b[39m, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# gpu\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 5️⃣ MAIN LOOP\n",
    "# ==========================================================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (frame_size_1, frame_size_2))\n",
    "\n",
    "    # masked_frame = cv2.bitwise_and(frame, road_mask)  # overlap mask and actual video to get only counting area\n",
    "\n",
    "    # Resize mask to match frame size\n",
    "    # mask_resized = cv2.resize(road_mask, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # Apply mask\n",
    "    frame_masked = cv2.bitwise_and(frame, frame, mask=road_mask)\n",
    "\n",
    "\n",
    "    # YOLO detection\n",
    "    # results = model(frame, verbose=False)   # cpu\n",
    "    results = model(frame_masked, device=0, verbose=False)  # gpu\n",
    "\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "\n",
    "            # conf = float(box.conf.cpu().numpy())\n",
    "\n",
    "            conf = box.conf.item()\n",
    "\n",
    "\n",
    "            if conf < CONF_THRESH:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
    "\n",
    "            plate_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # OCR\n",
    "            text = recognize_plate(plate_crop)\n",
    "\n",
    "            # Stabilization\n",
    "            box_id = get_box_id(x1, y1, x2, y2)\n",
    "            stable_text = get_stable_plate(box_id, text)\n",
    "\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 3)\n",
    "\n",
    "            # Overlay zoomed plate\n",
    "            if plate_crop.size > 0:\n",
    "\n",
    "                overlay_h, overlay_w = 150, 400\n",
    "                plate_resized = cv2.resize(\n",
    "                    plate_crop,\n",
    "                    (overlay_w, overlay_h)\n",
    "                )\n",
    "\n",
    "                oy1 = max(0, y1 - overlay_h - 40)\n",
    "                ox1 = x1\n",
    "                oy2 = oy1 + overlay_h\n",
    "                ox2 = ox1 + overlay_w\n",
    "\n",
    "                if oy2 <= frame.shape[0] and ox2 <= frame.shape[1]:\n",
    "                    frame[oy1:oy2, ox1:ox2] = plate_resized\n",
    "\n",
    "                    # Text with black outline\n",
    "                    cv2.putText(\n",
    "                        frame, stable_text,\n",
    "                        (ox1, oy1 - 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        2, (0,0,0), 6\n",
    "                    )\n",
    "\n",
    "                    # White text\n",
    "                    cv2.putText(\n",
    "                        frame, stable_text,\n",
    "                        (ox1, oy1 - 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        2, (255,255,255), 3\n",
    "                    )\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Annotated Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CLEANUP\n",
    "# ==========================================================\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"✅ Processing complete. Video saved:\", output_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
